<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Thomas Quinn" />

<meta name="date" content="2019-03-23" />

<title>Advanced Topics for the exprso Package</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Advanced Topics for the exprso Package</h1>
<h4 class="author"><em>Thomas Quinn</em></h4>
<h4 class="date"><em>2019-03-23</em></h4>



<div id="foreword" class="section level2">
<h2>Foreword</h2>
<p>Although this vignette contains a lot of exciting stuff, to get the most out of it, we recommend first reading the companion vignette, “An Introduction to the exprso Package”, which introduces many of the core features applied here.</p>
</div>
<div id="tidy-learning" class="section level2">
<h2>Tidy learning</h2>
<p>All exprso modules support piping with the magrittr package. Piping is handled by two key functions, <code>%&gt;%</code> and <code>%T&gt;%</code>, that pass the result from a prior function call to the first argument of the next function call. However, the latter differs from the former in that it “branches out” and does not pass on its own result. Instead, <code>%T&gt;%</code> pipes along the result from the previous function, making it useful for “side-chain” tasks like plotting. First, let us load some data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(exprso)
<span class="kw">library</span>(magrittr)
<span class="kw">data</span>(iris)
array &lt;-<span class="st"> </span><span class="kw">exprso</span>(iris[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>], iris[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="dv">5</span>])</code></pre></div>
<pre><code>## [1] &quot;Preparing data for binary classification.&quot;
## [1] &quot;Converting binary labels to CONTROL / CASE.&quot;
## [1] &quot;CONTROL: setosa (override with 'switch')&quot;</code></pre>
<p>Below, we use the <code>%&gt;%</code> function to pre-process the data and split it into a training and test set. Since the data object forks at the level of the <code>split</code> method (yielding two <code>ExprsArray</code> objects from one), it makes sense to break the pipe cascade there.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">splitSets &lt;-<span class="st"> </span>array <span class="op">%&gt;%</span>
<span class="st">  </span>modTransform <span class="op">%&gt;%</span><span class="st"> </span>modNormalize <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">splitSample</span>(<span class="dt">percent.include =</span> <span class="dv">67</span>)</code></pre></div>
<p>Next, we use the <code>%&gt;%</code> function to pull the training set from the <code>split</code> method result (via the <code>trainingSet</code> function) and pipe it through a chain of feature selection and classifier construction methods. Similar to <code>trainingSet</code>, the <code>testSet</code> function (or, equivalently, the <code>validationSet</code> function) will extract the test set from the <code>split</code> method result.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred &lt;-<span class="st"> </span><span class="kw">trainingSet</span>(splitSets) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">fsStats</span>(<span class="dt">how =</span> <span class="st">&quot;t.test&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">fsPrcomp</span>(<span class="dt">top =</span> <span class="dv">2</span>) <span class="op">%T&gt;%</span>
<span class="st">  </span><span class="kw">plot</span>(<span class="dt">c =</span> <span class="dv">0</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>buildSVM <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">predict</span>(<span class="kw">testSet</span>(splitSets)) <span class="op">%T&gt;%</span>
<span class="st">  </span>calcStats</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --><img src="data:image/png;base64,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" /><!-- --></p>
<p>Piping can expedite ensemble classifier construction as well. Here, we use the <code>%&gt;%</code> function in conjunction with <code>plMonteCarlo</code> to (a) split the <em>training set</em> across 10 bootstraps, (b) perform a feature selection on each <em>training subset</em>, (c) construct an LDA classifier, and (d) deploy the classifier on an <em>internal validation set</em>. Then, we select the best three performing classifiers, regardless of the bootstrap origin, by passing the results through <code>pipeUnboot</code> and <code>pipeFilter</code> (see <code>?pipeUnboot</code> and <code>?pipeFilter</code> to learn more about how the “boot” column changes <code>pipeFilter</code> behavior). Last, we build a classifier ensemble and deploy it on the <em>test set</em>. For code clarity, we define the argument handler functions <code>ctrlSplitSet</code>, <code>ctrlFeatureSelect</code>, and <code>ctrlGridSearch</code> outside of the pipe cascade.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ss &lt;-<span class="st"> </span><span class="kw">ctrlSplitSet</span>(<span class="dt">func =</span> <span class="st">&quot;splitSample&quot;</span>, <span class="dt">percent.include =</span> <span class="dv">67</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
fs &lt;-<span class="st"> </span><span class="kw">ctrlFeatureSelect</span>(<span class="dt">func =</span> <span class="st">&quot;fsStats&quot;</span>, <span class="dt">top =</span> <span class="dv">0</span>)
gs &lt;-<span class="st"> </span><span class="kw">ctrlGridSearch</span>(<span class="dt">func =</span> <span class="st">&quot;plGrid&quot;</span>, <span class="dt">top =</span> <span class="dv">0</span>, <span class="dt">how =</span> <span class="st">&quot;buildLDA&quot;</span>)

pred &lt;-<span class="st"> </span><span class="kw">trainingSet</span>(splitSets) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plMonteCarlo</span>(<span class="dt">B =</span> <span class="dv">10</span>, <span class="dt">ctrlSS =</span> ss, <span class="dt">ctrlFS =</span> fs, <span class="dt">ctrlGS =</span> gs) <span class="op">%&gt;%</span>
<span class="st">  </span>pipeUnboot <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pipeFilter</span>(<span class="dt">colBy =</span> <span class="st">&quot;valid.auc&quot;</span>, <span class="dt">top =</span> <span class="dv">3</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>buildEnsemble <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">predict</span>(<span class="kw">testSet</span>(splitSets)) <span class="op">%T&gt;%</span>
<span class="st">  </span>calcStats</code></pre></div>
</div>
<div id="clustering-before-classifying" class="section level2">
<h2>Clustering before classifying</h2>
<p>The exprso package also includes an experimental function, <code>modCluster</code>, that clusters subjects prior to building models. This function uses the <code>how</code> argument to toggle between one of seven clustering algorithms and returns an <code>ExprsArray</code> object with updated <code>@annot</code> slot that contains the results of clustering.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred &lt;-<span class="st"> </span><span class="kw">trainingSet</span>(splitSets) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">modCluster</span>(<span class="dt">top =</span> <span class="dv">0</span>, <span class="dt">how =</span> <span class="st">&quot;hclust&quot;</span>, <span class="dt">k =</span> <span class="dv">4</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">modSubset</span>(<span class="dt">colBy =</span> <span class="st">&quot;cluster&quot;</span>, <span class="dt">include =</span> <span class="dv">1</span>)</code></pre></div>
<p>Next, we show how to make a custom training set based on a cluster of cases and all controls. For this, we use <code>modCluster</code> in conjunction with the <code>conjoin</code> function. Note that using <code>conjoin</code> after feature selection will throw an error. Although we cluster cases here, this technique would work for any data annotation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">clusteredCases &lt;-<span class="st"> </span><span class="kw">trainingSet</span>(splitSets) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">modSubset</span>(<span class="dt">colBy =</span> <span class="st">&quot;defineCase&quot;</span>, <span class="dt">include =</span> <span class="st">&quot;Case&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>modCluster <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">modSubset</span>(<span class="dt">colBy =</span> <span class="st">&quot;cluster&quot;</span>, <span class="dt">include =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">conjoin</span>(<span class="kw">trainingSet</span>(splitSets) <span class="op">%&gt;%</span>
<span class="st">            </span><span class="kw">modSubset</span>(<span class="dt">colBy =</span> <span class="st">&quot;defineCase&quot;</span>, <span class="dt">include =</span> <span class="st">&quot;Control&quot;</span>))</code></pre></div>
</div>
<div id="importing-gse-files" class="section level2">
<h2>Importing GSE files</h2>
<p>The NCBI GEO hosts files in GSE or GDS format, the latter being a curated version the former. These GDS data files easily convert to an <code>ExpressionSet</code> (abbreviated <code>eSet</code>) object using the <code>GDS2eSet</code> function from the GEOquery package. However, not all GSE data files have a corresponding GDS data file available. Instead, we can use the <code>GSE2eSet</code> function to build an <code>eSet</code> object from any GSE data file. The <code>arrayExprs</code> function imports an <code>eSet</code> object into exprso.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data.gse &lt;-<span class="st"> </span>GEOquery<span class="op">::</span><span class="kw">getGEO</span>(<span class="st">&quot;GSE5847&quot;</span>, <span class="dt">GSEMatrix =</span> <span class="ot">FALSE</span>)
data.eset &lt;-<span class="st"> </span><span class="kw">GSE2eSet</span>(data.gse)
data.eset<span class="op">@</span>phenoData<span class="op">@</span>data</code></pre></div>
</div>
<div id="deep-learning" class="section level2">
<h2>Deep learning</h2>
<p>Deep learning in exprso does not differ much from the other approaches to classification. However, supplying arguments can get cumbersome.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred &lt;-<span class="st"> </span><span class="kw">trainingSet</span>(splitSets) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">buildDNN</span>(<span class="dt">top =</span> <span class="dv">0</span>,
           <span class="dt">activation =</span> <span class="st">&quot;TanhWithDropout&quot;</span>, <span class="co"># or 'Tanh'</span>
           <span class="dt">input_dropout_ratio =</span> <span class="fl">0.2</span>, <span class="co"># % of inputs dropout</span>
           <span class="dt">hidden_dropout_ratios =</span> <span class="kw">c</span>(<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>), <span class="co"># % for nodes dropout</span>
           <span class="dt">balance_classes =</span> <span class="ot">TRUE</span>,
           <span class="dt">hidden =</span> <span class="kw">c</span>(<span class="dv">50</span>,<span class="dv">50</span>,<span class="dv">50</span>), <span class="co"># three layers of 50 nodes</span>
           <span class="dt">epochs =</span> <span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">predict</span>(<span class="kw">testSet</span>(splitSets)) <span class="op">%T&gt;%</span>
<span class="st">  </span>calcStats</code></pre></div>
<p>One important difference with <code>buildDNN</code> is that you must manually clear the old classification models from RAM. Unlike with other models, the <code>ExprsModel</code> object does not actually store the deep neural net, but rather just holds a “link” to the actual classifier which is stored outside of R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">h2o<span class="op">::</span><span class="kw">h2o.shutdown</span>() <span class="co"># frees up RAM for more learning</span></code></pre></div>
<p>When embedding <code>buildDNN</code> within a grid-search, we run into the difficulty that most <code>buildDNN</code> arguments require a numeric vector as input. These vector inputs typically correspond to a unique value for each layer of the deep neural net. We can provide <code>plGrid</code> a vector argument by wrapping it in a list. Take note that this approach of providing argument vectors in a list would also work for other arguments (e.g., character arguments to <code>top</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pl &lt;-<span class="st"> </span><span class="kw">trainingSet</span>(splitSets) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plGrid</span>(<span class="dt">array.valid =</span> <span class="kw">testSet</span>(splitSets), <span class="dt">top =</span> <span class="dv">0</span>,
         <span class="dt">how =</span> <span class="st">&quot;buildDNN&quot;</span>, <span class="dt">fold =</span> <span class="ot">NULL</span>,
         <span class="dt">activation =</span> <span class="st">&quot;TanhWithDropout&quot;</span>, <span class="co"># or 'Tanh'</span>
         <span class="dt">input_dropout_ratio =</span> <span class="fl">0.2</span>, <span class="co"># % of inputs dropout</span>
         <span class="dt">hidden_dropout_ratios =</span> <span class="kw">list</span>(<span class="kw">c</span>(<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>)), <span class="co"># % for nodes dropout</span>
         <span class="dt">balance_classes =</span> <span class="ot">TRUE</span>,
         <span class="dt">hidden =</span> <span class="kw">list</span>(<span class="kw">c</span>(<span class="dv">50</span>,<span class="dv">50</span>,<span class="dv">50</span>)), <span class="co"># three layers of 50 nodes</span>
         <span class="dt">epochs =</span> <span class="dv">100</span>)</code></pre></div>
<p>Below, we show a more elaborate deep learning grid-search. For details on these arguments, see <code>?h2o::h2o.deeplearning</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pl &lt;-<span class="st"> </span><span class="kw">trainingSet</span>(splitSets) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plGrid</span>(<span class="dt">array.valid =</span> <span class="kw">testSet</span>(splitSets), <span class="dt">top =</span> <span class="dv">0</span>,
         <span class="dt">how =</span> <span class="st">&quot;buildDNN&quot;</span>, <span class="dt">fold =</span> <span class="ot">NULL</span>,
         <span class="dt">activation =</span> <span class="kw">c</span>(<span class="st">&quot;Rectifier&quot;</span>,
                        <span class="st">&quot;TanhWithDropout&quot;</span>), <span class="co"># or 'Tanh'</span>
         <span class="dt">input_dropout_ratio =</span> <span class="kw">c</span>(<span class="fl">0.2</span>,
                                 <span class="fl">0.5</span>,
                                 <span class="fl">0.8</span>), <span class="co"># % of inputs dropout</span>
         <span class="dt">hidden_dropout_ratios =</span> <span class="kw">list</span>(<span class="kw">c</span>(<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>),
                                      <span class="kw">c</span>(<span class="fl">0.2</span>,<span class="fl">0.2</span>,<span class="fl">0.2</span>)), <span class="co"># % for nodes dropout</span>
         <span class="dt">balance_classes =</span> <span class="ot">TRUE</span>,
         <span class="dt">hidden =</span> <span class="kw">list</span>(<span class="kw">c</span>(<span class="dv">50</span>,<span class="dv">50</span>,<span class="dv">50</span>),
                       <span class="kw">c</span>(<span class="dv">100</span>,<span class="dv">100</span>,<span class="dv">100</span>),
                       <span class="kw">c</span>(<span class="dv">200</span>,<span class="dv">200</span>,<span class="dv">200</span>)), <span class="co"># three layers of 50 nodes</span>
         <span class="dt">epochs =</span> <span class="kw">c</span>(<span class="dv">100</span>))</code></pre></div>
<p>Keep in mind that deep learning is a very RAM hungry task. If you’re not careful, you’ll run out RAM and throw an error. Remember to call <code>h2o::h2o.shutdown()</code> whenever you finish!</p>
</div>
<div id="perfect-cross-validation" class="section level2">
<h2>Perfect cross-validation</h2>
<p>The “perfect” cross-validation pipeline would have two layers of cross-validation such that the <em>outer-layer</em> divides the data <em>without</em> feature selection while the <em>inner-layer</em> divides the data <em>with</em> feature selection. We can achieve this in exprso by embedding a <code>plNested</code> pipeline within another <code>plNested</code> pipeline.</p>
<p>If you use this approach, you should not need a test set as long as you calculate classification accuracy in a way that respects the independence of each fold. In other words, if you opt out of a <em>test set</em>, you must never let a <em>validation set</em> accuracy guide the selection of which training sets to use when calculating the final classification accuracy.</p>
<p>For illustrative purposes, we perform “perfect” cross-validation using support vector machines built across a single set of parameters. Extending this pipeline to a larger parameter grid-search will require a cautious analysis of the results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fs.inner &lt;-<span class="st"> </span><span class="kw">ctrlFeatureSelect</span>(<span class="dt">func =</span> <span class="st">&quot;fsStats&quot;</span>, <span class="dt">top =</span> <span class="dv">0</span>, <span class="dt">how =</span> <span class="st">&quot;t.test&quot;</span>)
gs.inner &lt;-<span class="st"> </span><span class="kw">ctrlGridSearch</span>(<span class="dt">func =</span> <span class="st">&quot;plGrid&quot;</span>, <span class="dt">top =</span> <span class="dv">3</span>,
                           <span class="dt">how =</span> <span class="st">&quot;buildSVM&quot;</span>, <span class="dt">fold =</span> <span class="ot">NULL</span>)

fs.outer &lt;-<span class="st"> </span><span class="kw">ctrlFeatureSelect</span>(<span class="dt">func =</span> <span class="st">&quot;fsNULL&quot;</span>, <span class="dt">top =</span> <span class="dv">0</span>)
gs.outer &lt;-<span class="st"> </span><span class="kw">ctrlGridSearch</span>(<span class="dt">func =</span> <span class="st">&quot;plNested&quot;</span>, <span class="dt">fold =</span> <span class="dv">2</span>,
                           <span class="dt">ctrlFS =</span> fs.inner, <span class="dt">ctrlGS =</span> gs.inner)

pl &lt;-<span class="st"> </span>array <span class="op">%&gt;%</span>
<span class="st">  </span>modTransform <span class="op">%&gt;%</span><span class="st"> </span>modNormalize <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plNested</span>(<span class="dt">fold =</span> <span class="dv">2</span>, <span class="dt">ctrlFS =</span> fs.outer, <span class="dt">ctrlGS =</span> gs.outer)</code></pre></div>
</div>
<div id="cross-validation-variants" class="section level2">
<h2>Cross-validation variants</h2>
<p>Typically, we summarize rounds of cross-validation using accuracy. However, we could conceive of situations where we might want to emphasize sensitivity over specificity (or <em>vice versa</em>). Below, we show how we can use <code>plNested</code> in lieu of <code>plCV</code> to select <code>plMonteCarlo</code> bootstraps based on sensitivity.</p>
<p>In this example, each iteration of <code>plMonteCarlo</code> will split the dataset, then call <code>plNested</code> on the training subset. Next, <code>plNested</code> will manage <span class="math inline">\(v\)</span>-fold cross-validation, splitting the data into <span class="math inline">\(v\)</span> equal folds. Finally, each fold will undergo a grid-search according to <code>plGrid</code>. Since we have chosen to use <code>plNested</code> in lieu of <code>plCV</code>, we disable <code>plCV</code> by setting the <code>plGrid</code> argument <code>fold = NULL</code>. Note that, as above, we only perform feature selection within the <em>inner-layer</em>. This ensures that the <em>outer-layer</em> serves as a truly independent <em>validation set</em>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fs.inner &lt;-<span class="st"> </span><span class="kw">ctrlFeatureSelect</span>(<span class="dt">func =</span> <span class="st">&quot;fsStats&quot;</span>, <span class="dt">top =</span> <span class="dv">0</span>, <span class="dt">how =</span> <span class="st">&quot;t.test&quot;</span>)
gs.inner &lt;-<span class="st"> </span><span class="kw">ctrlGridSearch</span>(<span class="dt">func =</span> <span class="st">&quot;plGrid&quot;</span>, <span class="dt">top =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>),
                           <span class="dt">how =</span> <span class="st">&quot;buildSVM&quot;</span>, <span class="dt">fold =</span> <span class="ot">NULL</span>)

ss.outer &lt;-<span class="st"> </span><span class="kw">ctrlSplitSet</span>(<span class="dt">func =</span> <span class="st">&quot;splitStratify&quot;</span>, <span class="dt">percent.include =</span> <span class="dv">67</span>)
fs.outer &lt;-<span class="st"> </span><span class="kw">ctrlFeatureSelect</span>(<span class="dt">func =</span> <span class="st">&quot;fsNULL&quot;</span>, <span class="dt">top =</span> <span class="dv">0</span>)
gs.outer &lt;-<span class="st"> </span><span class="kw">ctrlGridSearch</span>(<span class="dt">func =</span> <span class="st">&quot;plNested&quot;</span>, <span class="dt">fold =</span> <span class="dv">10</span>,
                           <span class="dt">ctrlFS =</span> fs.inner, <span class="dt">ctrlGS =</span> gs.inner)

pl &lt;-<span class="st"> </span>array <span class="op">%&gt;%</span>
<span class="st">  </span>modTransform <span class="op">%&gt;%</span><span class="st"> </span>modNormalize <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plMonteCarlo</span>(<span class="dt">B =</span> <span class="dv">5</span>, <span class="dt">ctrlSS =</span> ss.outer, <span class="dt">ctrlFS =</span> fs.outer, <span class="dt">ctrlGS =</span> gs.outer)</code></pre></div>
<p>The resultant object now contains the necessary information to rank <code>plMonteCarlo</code> bootstraps based on <span class="math inline">\(v\)</span>-fold cross-validation sensitivity or specificity. Alternatively, we could aggregate the results by selecting the best fold from each bootstrap using <code>pipeFilter</code>, emphasizing sensitivity over specificity with <code>colBy</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">top &lt;-
<span class="st">  </span><span class="kw">pipeFilter</span>(pl, <span class="dt">colBy =</span> <span class="kw">c</span>(<span class="st">&quot;valid.sens&quot;</span>, <span class="st">&quot;valid.sens&quot;</span>, <span class="st">&quot;valid.spec&quot;</span>), <span class="dt">top =</span> <span class="dv">1</span>)</code></pre></div>
</div>
<div id="multi-class-classification" class="section level2">
<h2>Multi-class classification</h2>
<p>The exprso package also contains a growing number of methods made specifically for dealing with multi-class data. For example, all of the <code>build</code> methods available for binary classification also work for multi-class classification. In addition, exprso also contains some feature selection methods that work for binary and multi-class data alike.</p>
<p>Below, we use mock multi-class data to illustrate a simple multi-class classification pipeline.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">splitSets &lt;-<span class="st"> </span><span class="kw">data</span>(arrayMulti) <span class="op">%&gt;%</span><span class="st"> </span>get <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">splitStratify</span>(<span class="dt">percent.include =</span> <span class="dv">67</span>, <span class="dt">colBy =</span> <span class="st">&quot;sex&quot;</span>)

<span class="kw">trainingSet</span>(splitSets) <span class="op">%&gt;%</span>
<span class="st">  </span>fsANOVA <span class="op">%&gt;%</span>
<span class="st">  </span>buildNB <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># any build method can become multi with 1-vs-all</span>
<span class="st">  </span><span class="kw">predict</span>(<span class="kw">testSet</span>(splitSets)) <span class="op">%T&gt;%</span>
<span class="st">  </span>calcStats</code></pre></div>
<p>All the pipelines developed for binary classification work equally well for multi-class classification. However, not all feature selection methods work for multi-class data. As long as you choose a valid multi-class feature selection method, <code>plGrid</code>, <code>plMonteCarlo</code>, and <code>plNested</code> will work without fail.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fs &lt;-<span class="st"> </span><span class="kw">ctrlFeatureSelect</span>(<span class="dt">func =</span> <span class="st">&quot;fsANOVA&quot;</span>, <span class="dt">top =</span> <span class="dv">0</span>)
gs &lt;-<span class="st"> </span><span class="kw">ctrlGridSearch</span>(<span class="dt">func =</span> <span class="st">&quot;plGrid&quot;</span>, <span class="dt">top =</span> <span class="dv">0</span>, <span class="dt">how =</span> <span class="st">&quot;buildRF&quot;</span>, <span class="dt">fold =</span> <span class="dv">2</span>)

pl &lt;-<span class="st"> </span><span class="kw">trainingSet</span>(splitSets) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plNested</span>(<span class="dt">fold =</span> <span class="dv">2</span>, <span class="dt">ctrlFS =</span> fs, <span class="dt">ctrlGS =</span> gs) <span class="op">%T&gt;%</span>
<span class="st">  </span><span class="kw">calcNested</span>(<span class="dt">colBy =</span> <span class="st">&quot;valid.acc&quot;</span>)</code></pre></div>
<p>Note that exprso also supports multi-class classifier ensembles.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pl <span class="op">%&gt;%</span><span class="st"> </span>buildEnsemble <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">predict</span>(<span class="kw">testSet</span>(splitSets)) <span class="op">%&gt;%</span>
<span class="st">  </span>calcStats</code></pre></div>
<p>A special <code>plGrid</code> variant, called <code>plGridMulti</code>, is also available for multi-class data. This variant uses <em>1-vs-all feature selection</em> instead of multi-class feature selection. In this implementation, 1-vs-all feature selection occurs just prior to 1-vs-all classifier construction. As such, each individual <code>ExprsMachine</code> within the <code>ExprsModule</code> will have its own unique feature selection history to pass on to the test set during classifier deployment. For <code>plGridMulti</code>, the 1-vs-all feature selection is managed just like the other <code>pl</code> functions, using the <code>ctrlFeatureSelect</code> argument handler.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fs &lt;-<span class="st"> </span><span class="kw">ctrlFeatureSelect</span>(<span class="dt">func =</span> <span class="st">&quot;fsStats&quot;</span>, <span class="dt">top =</span> <span class="dv">0</span>, <span class="dt">how =</span> <span class="st">&quot;t.test&quot;</span>)

pl &lt;-<span class="st"> </span><span class="kw">plGridMulti</span>(<span class="kw">trainingSet</span>(splitSets), <span class="kw">testSet</span>(splitSets),
                  <span class="dt">ctrlFS =</span> fs, <span class="dt">top =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>),
                  <span class="dt">how =</span> <span class="st">&quot;buildSVM&quot;</span>, <span class="dt">kernel =</span> <span class="kw">c</span>(<span class="st">&quot;linear&quot;</span>, <span class="st">&quot;radial&quot;</span>),
                  <span class="dt">gamma =</span> <span class="kw">c</span>(.<span class="dv">1</span>, <span class="fl">.2</span>))</code></pre></div>
<p>However, <code>plGridMulti</code> does not have built-in <code>plCV</code> support. Instead, use <code>plNested</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fs.inner &lt;-<span class="st"> </span><span class="kw">ctrlFeatureSelect</span>(<span class="dt">func =</span> <span class="st">&quot;fsStats&quot;</span>, <span class="dt">top =</span> <span class="dv">0</span>, <span class="dt">how =</span> <span class="st">&quot;t.test&quot;</span>)
fs.outer &lt;-<span class="st"> </span><span class="kw">ctrlFeatureSelect</span>(<span class="dt">func =</span> <span class="st">&quot;fsNULL&quot;</span>, <span class="dt">top =</span> <span class="dv">0</span>)
gs.outer &lt;-
<span class="st">  </span><span class="kw">ctrlGridSearch</span>(<span class="dt">func =</span> <span class="st">&quot;plGridMulti&quot;</span>, <span class="dt">ctrlFS =</span> fs.inner, <span class="dt">top =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>),
                 <span class="dt">how =</span> <span class="st">&quot;buildSVM&quot;</span>, <span class="dt">kernel =</span> <span class="kw">c</span>(<span class="st">&quot;linear&quot;</span>, <span class="st">&quot;radial&quot;</span>), <span class="dt">gamma =</span> <span class="kw">c</span>(.<span class="dv">1</span>, <span class="fl">.2</span>))

pl &lt;-<span class="st"> </span><span class="kw">plNested</span>(<span class="kw">trainingSet</span>(splitSets), <span class="dt">fold =</span> <span class="dv">2</span>,
               <span class="dt">ctrlFS =</span> fs.outer, <span class="dt">ctrlGS =</span> gs.outer)</code></pre></div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
